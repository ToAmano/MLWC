{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pythonからC++へのbondlistの変換\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -----  ml.read_mol :: parse results... -------\n",
      " bonds_list ::  [[1, 7], [1, 0], [2, 3], [2, 8], [2, 1], [3, 9], [4, 2], [5, 0], [6, 1], [10, 4], [11, 4], [12, 4]]\n",
      " counter    ::  13\n",
      " atom_list  ::  ['O', 'C', 'C', 'O', 'C', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H']\n",
      " -----------------------------------------------\n",
      " ================ \n",
      " CH bonds...       [[1, 7], [2, 8], [6, 1], [10, 4], [11, 4], [12, 4]]\n",
      " CO bonds...       [[1, 0], [2, 3]]\n",
      " OH bonds...       [[3, 9], [5, 0]]\n",
      " OO bonds...       []\n",
      " CC bonds...       [[2, 1], [4, 2]]\n",
      " CC ring bonds...  []\n",
      " \n",
      "\n",
      " ================== \n",
      " ring_bond_index  []\n",
      " ch_bond_index    [0, 3, 8, 9, 10, 11]\n",
      " oh_bond_index    [5, 7]\n",
      " co_bond_index    [1, 2]\n",
      " cc_bond_index    [4, 6]\n",
      " ================ \n",
      " O atoms (lonepair)...       [0, 3]\n",
      " N atoms (lonepair)...       []\n",
      " C atoms ...                 [1, 2, 4]\n",
      " H atoms ...                 [5, 6, 7, 8, 9, 10, 11, 12]\n",
      "O 0.95 -0.02 0.07\n",
      "C 0.45 -0.07 -1.27\n",
      "C 0.95 1.14 -2.05\n",
      "O 2.38 1.14 -2.05\n",
      "C 0.47 1.12 -3.49\n",
      " -----  ml.read_mol :: parse results... -------\n",
      " representative_atom_index  :: 2\n",
      " -----------------------------------------------\n",
      " ================ \n",
      " coh_index/coc_index :: [oの番号, {coボンドの番号,ohボンドの番号}]\n",
      " TODO :: もしかしたらbond_indexを使った方が全体的にやりやすいかもしれない\n",
      " coh_index :: [[0, {'CO': 0, 'OH': 1}], [1, {'CO': 1, 'OH': 0}]]\n",
      " coc_index :: []\n",
      " ================ \n",
      " oh_bond_indexとco_bond_indexから，coc,cohに関わるバンドを削除した．\n",
      " co_without_index :: []\n",
      " oh_without_index :: []\n"
     ]
    }
   ],
   "source": [
    "import ml.atomtype\n",
    "# itpfilename=\"../../smiles/ppg725.acpype/input_GMX.mol\"\n",
    "itpfilename=\"../../smiles/pg.acpype/input_GMX.mol\"\n",
    "itp_data=ml.atomtype.read_mol(itpfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 O\n",
      "1 C\n",
      "2 C\n",
      "3 C\n",
      "4 O\n",
      "5 C\n",
      "6 C\n",
      "7 C\n",
      "8 O\n",
      "9 C\n",
      "10 C\n",
      "11 C\n",
      "12 O\n",
      "13 C\n",
      "14 C\n",
      "15 C\n",
      "16 O\n",
      "17 C\n",
      "18 C\n",
      "19 C\n",
      "20 O\n",
      "21 C\n",
      "22 C\n",
      "23 C\n",
      "24 O\n",
      "25 C\n",
      "26 C\n",
      "27 C\n",
      "28 O\n",
      "29 C\n",
      "30 C\n",
      "31 C\n",
      "32 O\n",
      "33 C\n",
      "34 C\n",
      "35 C\n",
      "36 O\n",
      "37 C\n",
      "38 C\n",
      "39 C\n",
      "40 O\n",
      "41 C\n",
      "42 C\n",
      "43 C\n",
      "44 O\n",
      "45 C\n",
      "46 C\n",
      "47 C\n",
      "48 O\n",
      "49 H\n",
      "50 H\n",
      "51 H\n",
      "52 H\n",
      "53 H\n",
      "54 H\n",
      "55 H\n",
      "56 H\n",
      "57 H\n",
      "58 H\n",
      "59 H\n",
      "60 H\n",
      "61 H\n",
      "62 H\n",
      "63 H\n",
      "64 H\n",
      "65 H\n",
      "66 H\n",
      "67 H\n",
      "68 H\n",
      "69 H\n",
      "70 H\n",
      "71 H\n",
      "72 H\n",
      "73 H\n",
      "74 H\n",
      "75 H\n",
      "76 H\n",
      "77 H\n",
      "78 H\n",
      "79 H\n",
      "80 H\n",
      "81 H\n",
      "82 H\n",
      "83 H\n",
      "84 H\n",
      "85 H\n",
      "86 H\n",
      "87 H\n",
      "88 H\n",
      "89 H\n",
      "90 H\n",
      "91 H\n",
      "92 H\n",
      "93 H\n",
      "94 H\n",
      "95 H\n",
      "96 H\n",
      "97 H\n",
      "98 H\n",
      "99 H\n",
      "100 H\n",
      "101 H\n",
      "102 H\n",
      "103 H\n",
      "104 H\n",
      "105 H\n",
      "106 H\n",
      "107 H\n",
      "108 H\n",
      "109 H\n",
      "110 H\n",
      "111 H\n",
      "112 H\n",
      "113 H\n",
      "114 H\n",
      "115 H\n",
      "116 H\n",
      "117 H\n",
      "118 H\n",
      "119 H\n",
      "120 H\n",
      "121 H\n",
      "122 H\n"
     ]
    }
   ],
   "source": [
    "for num,atom in enumerate(itp_data.atom_list):\n",
    "    print(num, atom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2\n",
      "1 52\n",
      "1 0\n",
      "2 53\n",
      "2 4\n",
      "3 55\n",
      "3 54\n",
      "3 2\n",
      "4 5\n",
      "5 58\n",
      "5 6\n",
      "5 57\n",
      "6 59\n",
      "6 7\n",
      "6 8\n",
      "7 61\n",
      "7 60\n",
      "8 9\n",
      "9 64\n",
      "9 63\n",
      "10 65\n",
      "10 11\n",
      "10 12\n",
      "10 9\n",
      "11 66\n",
      "11 68\n",
      "13 12\n",
      "13 70\n",
      "13 69\n",
      "14 71\n",
      "14 16\n",
      "14 13\n",
      "15 72\n",
      "15 74\n",
      "15 14\n",
      "17 16\n",
      "17 18\n",
      "18 77\n",
      "18 19\n",
      "18 20\n",
      "19 78\n",
      "19 79\n",
      "20 21\n",
      "21 22\n",
      "21 82\n",
      "22 83\n",
      "22 24\n",
      "23 85\n",
      "23 22\n",
      "24 25\n",
      "25 87\n",
      "25 26\n",
      "26 89\n",
      "26 27\n",
      "26 28\n",
      "27 92\n",
      "27 90\n",
      "29 28\n",
      "29 93\n",
      "30 95\n",
      "30 32\n",
      "30 31\n",
      "30 29\n",
      "31 98\n",
      "33 34\n",
      "33 32\n",
      "34 101\n",
      "34 35\n",
      "35 103\n",
      "35 104\n",
      "35 102\n",
      "36 34\n",
      "37 105\n",
      "37 36\n",
      "38 107\n",
      "38 39\n",
      "38 37\n",
      "39 109\n",
      "39 110\n",
      "40 38\n",
      "41 112\n",
      "41 111\n",
      "41 40\n",
      "42 113\n",
      "42 41\n",
      "43 42\n",
      "43 116\n",
      "44 42\n",
      "45 44\n",
      "45 117\n",
      "46 119\n",
      "46 45\n",
      "46 47\n",
      "47 122\n",
      "47 120\n",
      "48 46\n",
      "49 48\n",
      "50 0\n",
      "51 1\n",
      "56 3\n",
      "62 7\n",
      "67 11\n",
      "73 15\n",
      "75 17\n",
      "76 17\n",
      "80 19\n",
      "81 21\n",
      "84 23\n",
      "86 23\n",
      "88 25\n",
      "91 27\n",
      "94 29\n",
      "96 31\n",
      "97 31\n",
      "99 33\n",
      "100 33\n",
      "106 37\n",
      "108 39\n",
      "114 43\n",
      "115 43\n",
      "118 45\n",
      "121 47\n"
     ]
    }
   ],
   "source": [
    "for bond in itp_data.bonds_list:\n",
    "    print(bond[0],bond[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " nfeatures ::  288\n",
      "72\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "import torch       # ライブラリ「PyTorch」のtorchパッケージをインポート\n",
    "import torch.nn as nn  # 「ニューラルネットワーク」モジュールの別名定義\n",
    "\n",
    "class NET(nn.Module):\n",
    "    nfeatures = 288 # TODO :: hard code 4*12*6=288 # len(train_X_ch[0][0])\n",
    "    print(\" nfeatures :: \", nfeatures )\n",
    "\n",
    "    M = 20 \n",
    "    Mb= 6\n",
    "            \n",
    "    #Embedding Net \n",
    "    nfeatures_enet = int(nfeatures/4) # 72\n",
    "    print(nfeatures_enet)\n",
    "    # 定数（モデル定義時に必要となるもの）\n",
    "    INPUT_FEATURES_enet = nfeatures_enet      # 入力（特徴）の数： 記述子の数\n",
    "    LAYER1_NEURONS_enet = 50             # ニューロンの数\n",
    "    LAYER2_NEURONS_enet = 50             # ニューロンの数\n",
    "    OUTPUT_RESULTS_enet = M*nfeatures_enet    # 出力結果の数： \n",
    "\n",
    "    #Fitting Net \n",
    "    nfeatures_fnet = int(M*Mb) \n",
    "    print(nfeatures_fnet)\n",
    "    # 定数（モデル定義時に必要となるもの）\n",
    "    INPUT_FEATURES_fnet = nfeatures_fnet    # 入力（特徴）の数： 記述子の数\n",
    "    LAYER1_NEURONS_fnet = 50     # ニューロンの数\n",
    "    LAYER2_NEURONS_fnet = 50     # ニューロンの数\n",
    "    OUTPUT_RESULTS_fnet = M      # 出力結果の数：\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        ##### Embedding Net #####\n",
    "        # 隠れ層：1つ目のレイヤー（layer）\n",
    "        self.Enet_layer1 = nn.Linear(\n",
    "            self.INPUT_FEATURES_enet,                # 入力ユニット数（＝入力層）\n",
    "            self.LAYER1_NEURONS_enet)                # 次のレイヤーの出力ユニット数\n",
    "\n",
    "        # 隠れ層：2つ目のレイヤー（layer）\n",
    "        self.Enet_layer2 = nn.Linear(\n",
    "            self.LAYER1_NEURONS_enet,                # 入力ユニット数\n",
    "            self.LAYER2_NEURONS_enet)                # 次のレイヤーの出力ユニット数\n",
    "        \n",
    "        # 出力層\n",
    "        self.Enet_layer_out = nn.Linear(\n",
    "            self.LAYER2_NEURONS_enet,                # 入力ユニット数\n",
    "            self.OUTPUT_RESULTS_enet)                # 出力結果への出力ユニット数\n",
    "        \n",
    "        ##### Fitting net #####\n",
    "        # 隠れ層：1つ目のレイヤー（layer）\n",
    "        self.Fnet_layer1 = nn.Linear(\n",
    "            self.INPUT_FEATURES_fnet,                # 入力ユニット数（＝入力層）\n",
    "            self.LAYER1_NEURONS_fnet)                # 次のレイヤーの出力ユニット数\n",
    "        \n",
    "        # 隠れ層：2つ目のレイヤー（layer）\n",
    "        self.Fnet_layer2 = nn.Linear(\n",
    "            self.LAYER1_NEURONS_fnet,                # 入力ユニット数\n",
    "            self.LAYER2_NEURONS_fnet)                # 次のレイヤーの出力ユニット数\n",
    "        \n",
    "        # 出力層\n",
    "        self.Fnet_layer_out = nn.Linear(\n",
    "            self.LAYER2_NEURONS_fnet,                # 入力ユニット数\n",
    "            self.OUTPUT_RESULTS_fnet)                # 出力結果への出力ユニット数\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        #Si(1/Rをカットオフ関数で処理した値）のみを抽出する\n",
    "        Q1 = x[:,::4]\n",
    "        NB = Q1.size()[0]\n",
    "        N  = Q1.size()[1]\n",
    "        # Embedding Netに代入する \n",
    "        embedded_x = nn.functional.leaky_relu(self.Enet_layer1(Q1))  \n",
    "        embedded_x = nn.functional.leaky_relu(self.Enet_layer2(embedded_x)) \n",
    "        embedded_x = self.Enet_layer_out(embedded_x)  # ※最終層は線形 \n",
    "        #embedded_xを(ミニバッチデータ数)xMxN (N=MaxAt*原子種数)に変換\n",
    "        embedded_x = torch.reshape(embedded_x,(NB,self.M,N ))\n",
    "        #入力データをNB x N x 4 の行列に変形  \n",
    "        matQ = torch.reshape(x,(NB,N,4))\n",
    "        #Enetの出力との掛け算\n",
    "        matT = torch.matmul(embedded_x, matQ)\n",
    "        # matTの次元はNB x M x 4 となっている \n",
    "        #matSを作る(ハイパーパラメータMbで切り詰める)\n",
    "        matS = matT[:,:self.Mb,:]\n",
    "        #matSの転置行列を作る　→　NB x 4 x Mb となる \n",
    "        matSt = torch.transpose(matS, 1, 2)\n",
    "        #matDを作る( matTとmatStの掛け算) →　NB x M x Mb となる \n",
    "        matD = torch.matmul(matT, matSt)\n",
    "        #matDを１次元化する。matD全体をニューラルネットに入力したいので、ベクトル化する。 \n",
    "        matD1 = torch.reshape(matD,(NB,self.M*self.Mb))\n",
    "        # fitting Net に代入する \n",
    "        fitD = nn.functional.leaky_relu(self.Fnet_layer1(matD1))\n",
    "        fitD = nn.functional.leaky_relu(self.Fnet_layer2(fitD)) \n",
    "        fitD = self.Fnet_layer_out(fitD)  # ※最終層は線形 \n",
    "        # fitDの次元はNB x M となる。これをNB x 1 x Mの行列にする\n",
    "        fitD3 = torch.reshape(fitD,(NB,1,self.M))\n",
    "        # fttD3とmatTの掛け算 \n",
    "        matW = torch.matmul(fitD3, matT) \n",
    "        # matWはNb x 1 x  4 になっている。これをNB x 4 の2次元にする\n",
    "        matW2 = torch.reshape(matW,(NB,4))\n",
    "        # はじめの要素はいらないので、切り詰めてx,y,z にする\n",
    "        outW = matW2[:,1:]\n",
    "        \n",
    "        return outW\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------------------- \n",
      " loading ML variables from modeldir ... \n",
      "\n",
      "device :: check if use GPU :: cpu\n",
      "model_ch_2 :: NET(\n",
      "  (Enet_layer1): Linear(in_features=72, out_features=50, bias=True)\n",
      "  (Enet_layer2): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (Enet_layer_out): Linear(in_features=50, out_features=1440, bias=True)\n",
      "  (Fnet_layer1): Linear(in_features=120, out_features=50, bias=True)\n",
      "  (Fnet_layer2): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (Fnet_layer_out): Linear(in_features=50, out_features=20, bias=True)\n",
      ")\n",
      "model_co_2 :: NET(\n",
      "  (Enet_layer1): Linear(in_features=72, out_features=50, bias=True)\n",
      "  (Enet_layer2): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (Enet_layer_out): Linear(in_features=50, out_features=1440, bias=True)\n",
      "  (Fnet_layer1): Linear(in_features=120, out_features=50, bias=True)\n",
      "  (Fnet_layer2): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (Fnet_layer_out): Linear(in_features=50, out_features=20, bias=True)\n",
      ")\n",
      "model_oh_2 :: NET(\n",
      "  (Enet_layer1): Linear(in_features=72, out_features=50, bias=True)\n",
      "  (Enet_layer2): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (Enet_layer_out): Linear(in_features=50, out_features=1440, bias=True)\n",
      "  (Fnet_layer1): Linear(in_features=120, out_features=50, bias=True)\n",
      "  (Fnet_layer2): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (Fnet_layer_out): Linear(in_features=50, out_features=20, bias=True)\n",
      ")\n",
      "model_cc_2 :: NET(\n",
      "  (Enet_layer1): Linear(in_features=72, out_features=50, bias=True)\n",
      "  (Enet_layer2): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (Enet_layer_out): Linear(in_features=50, out_features=1440, bias=True)\n",
      "  (Fnet_layer1): Linear(in_features=120, out_features=50, bias=True)\n",
      "  (Fnet_layer2): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (Fnet_layer_out): Linear(in_features=50, out_features=20, bias=True)\n",
      ")\n",
      "model_o_2 :: NET(\n",
      "  (Enet_layer1): Linear(in_features=72, out_features=50, bias=True)\n",
      "  (Enet_layer2): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (Enet_layer_out): Linear(in_features=50, out_features=1440, bias=True)\n",
      "  (Fnet_layer1): Linear(in_features=120, out_features=50, bias=True)\n",
      "  (Fnet_layer2): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (Fnet_layer_out): Linear(in_features=50, out_features=20, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # モデル（NeuralNetworkクラス）のインスタンス化\n",
    "model_ring = NET()\n",
    "model_ch = NET()\n",
    "model_co = NET()\n",
    "model_cc = NET()\n",
    "model_oh = NET()\n",
    "model_o = NET()\n",
    "# <<<<<<<  if文ここまで <<<<<<<<\n",
    "try:\n",
    "    from torchinfo import summary\n",
    "    summary(model=model_ring)\n",
    "except ImportError:\n",
    "    print(\"WARNING :: torchinfo is not installed. skip printing model summary.\")\n",
    "    print(\"WARNING :: This has no effect on the calculation.\")\n",
    "\n",
    "# \n",
    "# * モデルをロードする場合はこれを利用する\n",
    "\n",
    "model_dir=\"/Volumes/portableSSD2T/14_pg/pg_cpmd/202306014_model_rotate/\" # PG用\n",
    "model_dir=\"./20230629_model_rotate/\" # PG2量体用\n",
    "model_dir=\"/Volumes/portableSSD2T/14_pg/pg_gromacs_bulk3_500K/20230721_model_rotate/\" # PG, 500K\n",
    "\n",
    "print(\" ------------------- \")\n",
    "print(\" loading ML variables from modeldir ... \")\n",
    "print(\"\")\n",
    "# model_dir=\"model_train40percent/\"\n",
    "# model_ring.load_state_dict(torch.load('model_ring_weight.pth'))\n",
    "\n",
    "#GPUが使用可能か確認\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device :: check if use GPU :: {}\".format(device))\n",
    "import os\n",
    "import torch.multiprocessing as mp\n",
    "if os.path.isfile(model_dir+'model_ch_weight.pth'):\n",
    "    model_ch.load_state_dict(torch.load(model_dir+'model_ch_weight.pth'))\n",
    "    model_ch_2 = model_ch.to(device) # 一旦モデルをcpuへ\n",
    "    print(\"model_ch_2 :: {}\".format(model_ch_2))\n",
    "    model_ch_2.share_memory() #https://knto-h.hatenablog.com/entry/2018/05/22/130745\n",
    "else:\n",
    "    print(\"model_ch_2 is not loaded\")\n",
    "if os.path.isfile(model_dir+'model_co_weight.pth'):\n",
    "    model_co.load_state_dict(torch.load(model_dir+'model_co_weight.pth'))\n",
    "    model_co_2 = model_co.to(device)\n",
    "    print(\"model_co_2 :: {}\".format(model_co_2))\n",
    "else:\n",
    "    print(\"model_co_2 is not loaded\")\n",
    "if os.path.isfile(model_dir+'model_oh_weight.pth'):\n",
    "    model_oh.load_state_dict(torch.load(model_dir+'model_oh_weight.pth'))\n",
    "    model_oh_2 = model_oh.to(device)\n",
    "    print(\"model_oh_2 :: {}\".format(model_oh_2))\n",
    "else:\n",
    "    print(\"model_oh_2 is not loaded\")\n",
    "if os.path.isfile(model_dir+'model_cc_weight.pth'):\n",
    "    model_cc.load_state_dict(torch.load(model_dir+'model_cc_weight.pth'))\n",
    "    model_cc_2 = model_cc.to(device)\n",
    "    print(\"model_cc_2 :: {}\".format(model_cc_2))\n",
    "else:\n",
    "    model_cc_2 = None\n",
    "    print(\"model_cc_2 is not loaded\")\n",
    "if os.path.isfile(model_dir+'model_o_weight.pth'):\n",
    "    model_o.load_state_dict(torch.load(model_dir+'model_o_weight.pth'))\n",
    "    model_o_2  = model_o.to(device)\n",
    "    print(\"model_o_2 :: {}\".format(model_o_2))\n",
    "else:\n",
    "    print(\"model_o_2 is not loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# * 学習時の形を決める必要がある．pythonの場合はvector対応できたがC++の場合にはそれができない点に注意が必要だ．．．\n",
    "import os\n",
    "\n",
    "# PG用\n",
    "if not os.path.isdir(\"202306014_model_rotate/\"):\n",
    "    os.mkdir(\"202306014_model_rotate/\")\n",
    "\n",
    "# PG2量体用\n",
    "if not os.path.isdir(\"20230629_model_rotate/\"):\n",
    "    os.mkdir(\"20230629_model_rotate/\")\n",
    "\n",
    "# PG500K用\n",
    "if not os.path.isdir(\"20230721_PG500K_model_rotate/\"):\n",
    "    os.mkdir(\"20230721_PG500K_model_rotate/\")\n",
    "\n",
    "\n",
    "modeldir = \"20230721_PG500K_model_rotate/\"\n",
    "\n",
    "# 学習時の入力サンプル\n",
    "example_input = torch.rand(1,288).to(device)\n",
    "\n",
    "# 学習済みモデルのトレース\n",
    "traced_net = torch.jit.trace(model_ch_2,example_input)\n",
    "# 変換モデルの出力\n",
    "traced_net.save(modeldir+\"model_ch.pt\")\n",
    "\n",
    "# 学習済みモデルのトレース\n",
    "traced_net = torch.jit.trace(model_co_2,example_input)\n",
    "# 変換モデルの出力\n",
    "traced_net.save(modeldir+\"model_co.pt\")\n",
    "\n",
    "\n",
    "# 学習済みモデルのトレース\n",
    "traced_net = torch.jit.trace(model_oh_2,example_input)\n",
    "# 変換モデルの出力\n",
    "traced_net.save(modeldir+\"model_oh.pt\")\n",
    "\n",
    "\n",
    "# 学習済みモデルのトレース\n",
    "traced_net = torch.jit.trace(model_cc_2,example_input)\n",
    "# 変換モデルの出力\n",
    "traced_net.save(modeldir+\"model_cc.pt\")\n",
    "\n",
    "# 学習済みモデルのトレース\n",
    "traced_net = torch.jit.trace(model_o_2,example_input)\n",
    "# 変換モデルの出力\n",
    "traced_net.save(modeldir+\"model_o.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_dieltools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
