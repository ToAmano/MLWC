{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pythonからC++へのモデルの出力\n",
    "\n",
    "https://tatsuya-note.com/trained-model-created-in-pytorch-in-cpp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " nfeatures ::  288\n",
      "72\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "import torch       # ライブラリ「PyTorch」のtorchパッケージをインポート\n",
    "import torch.nn as nn  # 「ニューラルネットワーク」モジュールの別名定義\n",
    "\n",
    "class NET(nn.Module):\n",
    "    nfeatures = 288 # TODO :: hard code 4*12*6=288 # len(train_X_ch[0][0])\n",
    "    print(\" nfeatures :: \", nfeatures )\n",
    "\n",
    "    M = 20 \n",
    "    Mb= 6\n",
    "            \n",
    "    #Embedding Net \n",
    "    nfeatures_enet = int(nfeatures/4) # 72\n",
    "    print(nfeatures_enet)\n",
    "    # 定数（モデル定義時に必要となるもの）\n",
    "    INPUT_FEATURES_enet = nfeatures_enet      # 入力（特徴）の数： 記述子の数\n",
    "    LAYER1_NEURONS_enet = 50             # ニューロンの数\n",
    "    LAYER2_NEURONS_enet = 50             # ニューロンの数\n",
    "    OUTPUT_RESULTS_enet = M*nfeatures_enet    # 出力結果の数： \n",
    "\n",
    "    #Fitting Net \n",
    "    nfeatures_fnet = int(M*Mb) \n",
    "    print(nfeatures_fnet)\n",
    "    # 定数（モデル定義時に必要となるもの）\n",
    "    INPUT_FEATURES_fnet = nfeatures_fnet    # 入力（特徴）の数： 記述子の数\n",
    "    LAYER1_NEURONS_fnet = 50     # ニューロンの数\n",
    "    LAYER2_NEURONS_fnet = 50     # ニューロンの数\n",
    "    OUTPUT_RESULTS_fnet = M      # 出力結果の数：\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        ##### Embedding Net #####\n",
    "        # 隠れ層：1つ目のレイヤー（layer）\n",
    "        self.Enet_layer1 = nn.Linear(\n",
    "            self.INPUT_FEATURES_enet,                # 入力ユニット数（＝入力層）\n",
    "            self.LAYER1_NEURONS_enet)                # 次のレイヤーの出力ユニット数\n",
    "\n",
    "        # 隠れ層：2つ目のレイヤー（layer）\n",
    "        self.Enet_layer2 = nn.Linear(\n",
    "            self.LAYER1_NEURONS_enet,                # 入力ユニット数\n",
    "            self.LAYER2_NEURONS_enet)                # 次のレイヤーの出力ユニット数\n",
    "        \n",
    "        # 出力層\n",
    "        self.Enet_layer_out = nn.Linear(\n",
    "            self.LAYER2_NEURONS_enet,                # 入力ユニット数\n",
    "            self.OUTPUT_RESULTS_enet)                # 出力結果への出力ユニット数\n",
    "        \n",
    "        ##### Fitting net #####\n",
    "        # 隠れ層：1つ目のレイヤー（layer）\n",
    "        self.Fnet_layer1 = nn.Linear(\n",
    "            self.INPUT_FEATURES_fnet,                # 入力ユニット数（＝入力層）\n",
    "            self.LAYER1_NEURONS_fnet)                # 次のレイヤーの出力ユニット数\n",
    "        \n",
    "        # 隠れ層：2つ目のレイヤー（layer）\n",
    "        self.Fnet_layer2 = nn.Linear(\n",
    "            self.LAYER1_NEURONS_fnet,                # 入力ユニット数\n",
    "            self.LAYER2_NEURONS_fnet)                # 次のレイヤーの出力ユニット数\n",
    "        \n",
    "        # 出力層\n",
    "        self.Fnet_layer_out = nn.Linear(\n",
    "            self.LAYER2_NEURONS_fnet,                # 入力ユニット数\n",
    "            self.OUTPUT_RESULTS_fnet)                # 出力結果への出力ユニット数\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        #Si(1/Rをカットオフ関数で処理した値）のみを抽出する\n",
    "        Q1 = x[:,::4]\n",
    "        NB = Q1.size()[0]\n",
    "        N  = Q1.size()[1]\n",
    "        # Embedding Netに代入する \n",
    "        embedded_x = nn.functional.leaky_relu(self.Enet_layer1(Q1))  \n",
    "        embedded_x = nn.functional.leaky_relu(self.Enet_layer2(embedded_x)) \n",
    "        embedded_x = self.Enet_layer_out(embedded_x)  # ※最終層は線形 \n",
    "        #embedded_xを(ミニバッチデータ数)xMxN (N=MaxAt*原子種数)に変換\n",
    "        embedded_x = torch.reshape(embedded_x,(NB,self.M,N ))\n",
    "        #入力データをNB x N x 4 の行列に変形  \n",
    "        matQ = torch.reshape(x,(NB,N,4))\n",
    "        #Enetの出力との掛け算\n",
    "        matT = torch.matmul(embedded_x, matQ)\n",
    "        # matTの次元はNB x M x 4 となっている \n",
    "        #matSを作る(ハイパーパラメータMbで切り詰める)\n",
    "        matS = matT[:,:self.Mb,:]\n",
    "        #matSの転置行列を作る　→　NB x 4 x Mb となる \n",
    "        matSt = torch.transpose(matS, 1, 2)\n",
    "        #matDを作る( matTとmatStの掛け算) →　NB x M x Mb となる \n",
    "        matD = torch.matmul(matT, matSt)\n",
    "        #matDを１次元化する。matD全体をニューラルネットに入力したいので、ベクトル化する。 \n",
    "        matD1 = torch.reshape(matD,(NB,self.M*self.Mb))\n",
    "        # fitting Net に代入する \n",
    "        fitD = nn.functional.leaky_relu(self.Fnet_layer1(matD1))\n",
    "        fitD = nn.functional.leaky_relu(self.Fnet_layer2(fitD)) \n",
    "        fitD = self.Fnet_layer_out(fitD)  # ※最終層は線形 \n",
    "        # fitDの次元はNB x M となる。これをNB x 1 x Mの行列にする\n",
    "        fitD3 = torch.reshape(fitD,(NB,1,self.M))\n",
    "        # fttD3とmatTの掛け算 \n",
    "        matW = torch.matmul(fitD3, matT) \n",
    "        # matWはNb x 1 x  4 になっている。これをNB x 4 の2次元にする\n",
    "        matW2 = torch.reshape(matW,(NB,4))\n",
    "        # はじめの要素はいらないので、切り詰めてx,y,z にする\n",
    "        outW = matW2[:,1:]\n",
    "        \n",
    "        return outW\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------------------- \n",
      " loading ML variables from modeldir ... \n",
      "\n",
      "device :: check if use GPU :: cpu\n",
      "model_ch_2 is not loaded\n",
      "model_co_2 is not loaded\n",
      "model_oh_2 is not loaded\n",
      "model_cc_2 is not loaded\n",
      "model_o_2 is not loaded\n",
      "model_coc_2 :: NET(\n",
      "  (Enet_layer1): Linear(in_features=72, out_features=50, bias=True)\n",
      "  (Enet_layer2): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (Enet_layer_out): Linear(in_features=50, out_features=1440, bias=True)\n",
      "  (Fnet_layer1): Linear(in_features=120, out_features=50, bias=True)\n",
      "  (Fnet_layer2): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (Fnet_layer_out): Linear(in_features=50, out_features=20, bias=True)\n",
      ")\n",
      "model_coh_2 :: NET(\n",
      "  (Enet_layer1): Linear(in_features=72, out_features=50, bias=True)\n",
      "  (Enet_layer2): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (Enet_layer_out): Linear(in_features=50, out_features=1440, bias=True)\n",
      "  (Fnet_layer1): Linear(in_features=120, out_features=50, bias=True)\n",
      "  (Fnet_layer2): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (Fnet_layer_out): Linear(in_features=50, out_features=20, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # モデル（NeuralNetworkクラス）のインスタンス化\n",
    "model_ring = NET()\n",
    "model_ch = NET()\n",
    "model_co = NET()\n",
    "model_cc = NET()\n",
    "model_oh = NET()\n",
    "model_o = NET()\n",
    "model_coc = NET()\n",
    "model_coh = NET()\n",
    "# <<<<<<<  if文ここまで <<<<<<<<\n",
    "try:\n",
    "    from torchinfo import summary\n",
    "    summary(model=model_ring)\n",
    "except ImportError:\n",
    "    print(\"WARNING :: torchinfo is not installed. skip printing model summary.\")\n",
    "    print(\"WARNING :: This has no effect on the calculation.\")\n",
    "\n",
    "# \n",
    "# * モデルをロードする場合はこれを利用する\n",
    "\n",
    "model_dir=\"/Volumes/portableSSD2T/14_pg/pg_cpmd/202306014_model_rotate/\" # PG用\n",
    "model_dir=\"./20230629_model_rotate/\" # PG2量体用\n",
    "model_dir=\"/Volumes/portableSSD2T/14_pg/pg_gromacs_bulk3_500K/20230721_model_rotate/\" # PG, 500K\n",
    "model_dir=\"/Volumes/portableSSD2T/14_pg/ppg725/bulk/20230719_model_rotate/\" #PPG725, 300K\n",
    "model_dir=\"/Volumes/portableSSD2T/14_pg/pg2_new_bulk/20230719_model_rotate_COC/\" #PG2のCOC,COHモデル(これは失敗モデル？)\n",
    "model_dir=\"/Volumes/portableSSD2T/14_pg/pg2_new_bulk/20230720_model_rotate_COC/\" #PG2のCOC,COHモデル\n",
    "\n",
    "\n",
    "print(\" ------------------- \")\n",
    "print(\" loading ML variables from modeldir ... \")\n",
    "print(\"\")\n",
    "# model_dir=\"model_train40percent/\"\n",
    "# model_ring.load_state_dict(torch.load('model_ring_weight.pth'))\n",
    "\n",
    "#GPUが使用可能か確認\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device :: check if use GPU :: {}\".format(device))\n",
    "import os\n",
    "import torch.multiprocessing as mp\n",
    "if os.path.isfile(model_dir+'model_ch_weight.pth'):\n",
    "    model_ch.load_state_dict(torch.load(model_dir+'model_ch_weight.pth'))\n",
    "    model_ch_2 = model_ch.to(device) # 一旦モデルをcpuへ\n",
    "    print(\"model_ch_2 :: {}\".format(model_ch_2))\n",
    "    model_ch_2.share_memory() #https://knto-h.hatenablog.com/entry/2018/05/22/130745\n",
    "else:\n",
    "    print(\"model_ch_2 is not loaded\")\n",
    "if os.path.isfile(model_dir+'model_co_weight.pth'):\n",
    "    model_co.load_state_dict(torch.load(model_dir+'model_co_weight.pth'))\n",
    "    model_co_2 = model_co.to(device)\n",
    "    print(\"model_co_2 :: {}\".format(model_co_2))\n",
    "else:\n",
    "    print(\"model_co_2 is not loaded\")\n",
    "if os.path.isfile(model_dir+'model_oh_weight.pth'):\n",
    "    model_oh.load_state_dict(torch.load(model_dir+'model_oh_weight.pth'))\n",
    "    model_oh_2 = model_oh.to(device)\n",
    "    print(\"model_oh_2 :: {}\".format(model_oh_2))\n",
    "else:\n",
    "    print(\"model_oh_2 is not loaded\")\n",
    "if os.path.isfile(model_dir+'model_cc_weight.pth'):\n",
    "    model_cc.load_state_dict(torch.load(model_dir+'model_cc_weight.pth'))\n",
    "    model_cc_2 = model_cc.to(device)\n",
    "    print(\"model_cc_2 :: {}\".format(model_cc_2))\n",
    "else:\n",
    "    model_cc_2 = None\n",
    "    print(\"model_cc_2 is not loaded\")\n",
    "if os.path.isfile(model_dir+'model_o_weight.pth'):\n",
    "    model_o.load_state_dict(torch.load(model_dir+'model_o_weight.pth'))\n",
    "    model_o_2  = model_o.to(device)\n",
    "    print(\"model_o_2 :: {}\".format(model_o_2))\n",
    "else:\n",
    "    print(\"model_o_2 is not loaded\")\n",
    "\n",
    "# 以下COC/COHモデル用\n",
    "if os.path.isfile(model_dir+'model_coc_weight4.pth'):\n",
    "    model_coc.load_state_dict(torch.load(model_dir+'model_coc_weight4.pth'))\n",
    "    model_coc_2  = model_coc.to(device)\n",
    "    print(\"model_coc_2 :: {}\".format(model_coc_2))\n",
    "else:\n",
    "    print(\"model_coc_2 is not loaded\")\n",
    "if os.path.isfile(model_dir+'model_coh_weight4.pth'):\n",
    "    model_coh.load_state_dict(torch.load(model_dir+'model_coh_weight4.pth'))\n",
    "    model_coh_2  = model_coh.to(device)\n",
    "    print(\"model_coh_2 :: {}\".format(model_coh_2))\n",
    "else:\n",
    "    print(\"model_coh_2 is not loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# * 学習時の形を決める必要がある．pythonの場合はvector対応できたがC++の場合にはそれができない点に注意が必要だ．．．\n",
    "import os\n",
    "\n",
    "# PG用\n",
    "if not os.path.isdir(\"202306014_model_rotate/\"):\n",
    "    os.mkdir(\"202306014_model_rotate/\")\n",
    "\n",
    "# PG2量体用\n",
    "if not os.path.isdir(\"20230629_model_rotate/\"):\n",
    "    os.mkdir(\"20230629_model_rotate/\")\n",
    "\n",
    "# PG500K用\n",
    "if not os.path.isdir(\"20230721_PG500K_model_rotate/\"):\n",
    "    os.mkdir(\"20230721_PG500K_model_rotate/\")\n",
    "\n",
    "# PPG725用\n",
    "if not os.path.isdir(\"20230719_PPG725_model_rotate/\"):\n",
    "    os.mkdir(\"20230719_PPG725_model_rotate/\")\n",
    "\n",
    "# PG2のCOC,COH用\n",
    "if not os.path.isdir(\"20230719_PG2_model_rotate_COC/\"):\n",
    "    os.mkdir(\"20230719_PG2_model_rotate_COC/\")\n",
    "\n",
    "# PG2のCOC,COH用\n",
    "if not os.path.isdir(\"20230720_PG2_model_rotate_COC/\"):\n",
    "    os.mkdir(\"20230720_PG2_model_rotate_COC/\")\n",
    "\n",
    "modeldir = \"20230720_PG2_model_rotate_COC/\"\n",
    "\n",
    "# 学習時の入力サンプル\n",
    "example_input = torch.rand(1,288).to(device)\n",
    "\n",
    "# 学習済みモデルのトレース\n",
    "traced_net = torch.jit.trace(model_ch_2,example_input)\n",
    "# 変換モデルの出力\n",
    "traced_net.save(modeldir+\"model_ch.pt\")\n",
    "\n",
    "# 学習済みモデルのトレース\n",
    "traced_net = torch.jit.trace(model_co_2,example_input)\n",
    "# 変換モデルの出力\n",
    "traced_net.save(modeldir+\"model_co.pt\")\n",
    "\n",
    "\n",
    "# 学習済みモデルのトレース\n",
    "traced_net = torch.jit.trace(model_oh_2,example_input)\n",
    "# 変換モデルの出力\n",
    "traced_net.save(modeldir+\"model_oh.pt\")\n",
    "\n",
    "\n",
    "# 学習済みモデルのトレース\n",
    "traced_net = torch.jit.trace(model_cc_2,example_input)\n",
    "# 変換モデルの出力\n",
    "traced_net.save(modeldir+\"model_cc.pt\")\n",
    "\n",
    "# 学習済みモデルのトレース\n",
    "traced_net = torch.jit.trace(model_o_2,example_input)\n",
    "# 変換モデルの出力\n",
    "traced_net.save(modeldir+\"model_o.pt\")\n",
    "\n",
    "# 学習済みモデルのトレース\n",
    "traced_net = torch.jit.trace(model_coc_2,example_input)\n",
    "# 変換モデルの出力\n",
    "traced_net.save(modeldir+\"model_coc.pt\")\n",
    "\n",
    "# 学習済みモデルのトレース\n",
    "traced_net = torch.jit.trace(model_coh_2,example_input)\n",
    "# 変換モデルの出力\n",
    "traced_net.save(modeldir+\"model_coh.pt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_dieltools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
